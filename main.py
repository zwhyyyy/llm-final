from langchain_community.document_loaders import JSONLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.llms import HuggingFacePipeline
from langchain_core.documents import Document
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from transformers import BitsAndBytesConfig
import torch
import json
import time
import os
import shutil

# ä» pubmed_articles.json åŠ è½½æ•°æ®
print("æ­£åœ¨åŠ è½½åŒ»å­¦æ–‡çŒ®æ•°æ®...")
with open('pubmed_articles.json', 'r', encoding='utf-8') as f:
    medical_papers = json.load(f)

print(f"æˆåŠŸåŠ è½½ {len(medical_papers)} ç¯‡åŒ»å­¦æ–‡çŒ®")


# æ–¹æ³•2ï¼šå¦‚æœJSONæ•°æ®ä¸å¤§ï¼Œä¹Ÿå¯ä»¥ç›´æ¥è½¬æ¢ä¸ºDocumentå¯¹è±¡
def json_to_documents(json_data):
    """å°†JSONæ•°æ®ç›´æ¥è½¬æ¢ä¸ºDocumentå¯¹è±¡"""
    documents = []
    for paper in json_data:
        # è·³è¿‡æ²¡æœ‰æ‘˜è¦çš„æ–‡ç« 
        if not paper.get('abstract') or paper.get('abstract').strip() == '':
            continue

        # ç»„åˆæ ‡é¢˜å’Œæ‘˜è¦ä½œä¸ºå†…å®¹
        content = f"Title: {paper.get('title', '')}\nAbstract: {paper.get('abstract', '')}"

        # åˆ›å»ºå…ƒæ•°æ®
        metadata = {
            "pmid": paper.get("pmid", ""),
            "title": paper.get("title", ""),
            "authors": ", ".join(paper.get("authors", [])),
            "journal": paper.get("journal", {}).get("title", ""),
            "pub_date": f"{paper.get('pub_date', {}).get('year', '')}-{paper.get('pub_date', {}).get('month', '')}",
            "source": "medical_literature"
        }

        documents.append(Document(page_content=content, metadata=metadata))

    return documents


# ä½¿ç”¨æ–¹æ³•2ï¼ˆæ¨èï¼Œæ›´ç®€å•ï¼‰
documents = json_to_documents(medical_papers)
print(f"æˆåŠŸå¤„ç† {len(documents)} ç¯‡æœ‰æ•ˆæ–‡çŒ®ï¼ˆå·²è¿‡æ»¤æ— æ‘˜è¦çš„æ–‡ç« ï¼‰")

# 3. åˆ†å‰²æ–‡æœ¬
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=100,
    length_function=len,
)

texts = text_splitter.split_documents(documents)
print(f"æˆåŠŸåˆ†å‰² {len(texts)} ä¸ªæ–‡æœ¬å—")

# 4. åˆ›å»ºå‘é‡åº“ï¼ˆä½¿ç”¨BGEæ¨¡å‹ï¼Œæ›´ç¨³å®šï¼‰
print("æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹...")
max_retries = 3
retry_count = 0
embeddings = None

while retry_count < max_retries:
    try:
        # ä¼˜å…ˆå°è¯•ä½¿ç”¨ BGE æ¨¡å‹ï¼ˆæ›´å°æ›´ç¨³å®šï¼‰
        embeddings = HuggingFaceEmbeddings(
            model_name="BAAI/bge-small-en-v1.5",
            model_kwargs={'device': 'cuda:0' if torch.cuda.is_available() else 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        print("åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
        break
    except Exception as e:
        retry_count += 1
        if retry_count < max_retries:
            print(f"æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ({retry_count}/{max_retries})...")
            time.sleep(5)
        else:
            print(f"ä½¿ç”¨å¤‡ç”¨æ¨¡å‹...")
            try:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ›´å°çš„æ¨¡å‹
                embeddings = HuggingFaceEmbeddings(
                    model_name="sentence-transformers/all-MiniLM-L6-v2",
                    model_kwargs={'device': 'cuda:0' if torch.cuda.is_available() else 'cpu'}
                )
                print("å¤‡ç”¨åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e2:
                print(f"æ‰€æœ‰åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥: {e2}")
                raise

# å¦‚æœæ•°æ®åº“å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤ï¼ˆé¿å…ç»´åº¦ä¸åŒ¹é…ï¼‰
db_path = "./chroma_medical_papers_db"
if os.path.exists(db_path):
    print("æ£€æµ‹åˆ°æ—§çš„å‘é‡æ•°æ®åº“ï¼Œæ­£åœ¨åˆ é™¤ä»¥é¿å…ç»´åº¦ä¸åŒ¹é…...")
    shutil.rmtree(db_path)
    print("æ—§æ•°æ®åº“å·²åˆ é™¤")

# åˆ›å»ºChromaå‘é‡å­˜å‚¨ï¼ˆæ›¿ä»£FAISSï¼ŒWindowsä¸Šæ›´ç¨³å®šï¼‰
print("æ­£åœ¨åˆ›å»ºå‘é‡æ•°æ®åº“...")
vectorstore = Chroma.from_documents(
    documents=texts,
    embedding=embeddings,
    persist_directory=db_path  # æŒä¹…åŒ–ç›®å½•
)
print("å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆ")

# 5. åˆå§‹åŒ–Qwen2.5-1.5B-Instructæ¨¡å‹ï¼ˆä½¿ç”¨é‡åŒ–ä»¥å‡å°‘å†…å­˜å ç”¨ï¼‰
print("æ­£åœ¨åŠ è½½Qwen2.5-1.5B-Instructæ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰...")

# é…ç½®4ä½é‡åŒ–
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
)

llm = HuggingFacePipeline.from_model_id(
    model_id="Qwen/Qwen2.5-1.5B-Instruct",
    task="text-generation",
    device=0 if torch.cuda.is_available() else -1,
    model_kwargs={
        "torch_dtype": torch.float16,
        "quantization_config": quantization_config,
    },
    pipeline_kwargs={
        "max_new_tokens": 512,
        "temperature": 0.1,
        "do_sample": True,
    }
)
print("æ¨¡å‹åŠ è½½å®Œæˆ")

# 6. åˆ›å»ºæ£€ç´¢å™¨ï¼ˆå¢åŠ æ£€ç´¢æ•°é‡ä»¥æé«˜å¬å›ç‡ï¼‰
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 5}  # å¢åŠ åˆ°5ä¸ªä»¥æé«˜ç›¸å…³æ–‡æ¡£çš„å¬å›
)

# 7. åˆ›å»ºåŒ»ç–—ä¸“ç”¨çš„æç¤ºæ¨¡æ¿ï¼ˆä¼˜åŒ–ä»¥é¿å…æ¨¡æ¿å†…å®¹è¢«è¾“å‡ºï¼‰
medical_prompt_template = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»å­¦ç ”ç©¶åŠ©æ‰‹ã€‚ä½ éœ€è¦åŸºäºæä¾›çš„åŒ»å­¦æ–‡çŒ®å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
æ³¨æ„:
1. ä»…æ ¹æ®æä¾›çš„æ–‡çŒ®å†…å®¹å›ç­”
2. å¦‚æœæ–‡çŒ®ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·
3. ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œä¸è¦é‡å¤é—®é¢˜æˆ–æ–‡çŒ®å†…å®¹
4. å›ç­”è¦ç®€æ´ä¸“ä¸š

å‚è€ƒæ–‡çŒ®:
{context}

é—®é¢˜ï¼š{question}
"""

PROMPT = PromptTemplate(
    template=medical_prompt_template,
    input_variables=["context", "question"]
)


# æ ¼å¼åŒ–æ–‡æ¡£çš„å‡½æ•°
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)


# ä½¿ç”¨è‡ªå®šä¹‰æç¤ºçš„QAé“¾ï¼ˆLangChain 1.0 æ–°APIï¼‰
def retrieve_and_format(question_dict):
    """æ£€ç´¢æ–‡æ¡£å¹¶æ ¼å¼åŒ–"""
    question = question_dict["question"]
    docs = retriever.invoke(question)
    return {
        "context": format_docs(docs),
        "question": question
    }

qa_chain = (
    RunnablePassthrough()
    | retrieve_and_format
    | PROMPT
    | llm
    | StrOutputParser()
)


# 8. ä¼˜åŒ–çš„æŸ¥è¯¢å‡½æ•°
def ask_medical_question(question):
    """æé—®å‡½æ•° - ä¼˜åŒ–è¾“å‡ºæ ¼å¼å’Œæ–‡çŒ®å±•ç¤º"""
    print("\n" + "="*80)
    print(f"â“ é—®é¢˜: {question}")
    print("="*80)

    # è·å–ç›¸å…³æ–‡æ¡£ï¼ˆå¸¦ç›¸å…³æ€§è¯„åˆ†ï¼‰
    docs_with_scores = vectorstore.similarity_search_with_relevance_scores(question, k=5)
    
    # è¿‡æ»¤ä½ç›¸å…³æ€§æ–‡æ¡£ï¼ˆç›¸å…³æ€§åˆ†æ•° > 0.3ï¼‰
    filtered_docs = [(doc, score) for doc, score in docs_with_scores if score > 0.3]
    
    if not filtered_docs:
        print("\nâš ï¸  æœªæ‰¾åˆ°ç›¸å…³æ–‡çŒ®ï¼Œæ— æ³•å›ç­”è¯¥é—®é¢˜ã€‚")
        return
    
    # ä½¿ç”¨è¿‡æ»¤åçš„æ–‡æ¡£
    docs = [doc for doc, score in filtered_docs]
    
    # ä½¿ç”¨é“¾è¿›è¡Œé—®ç­”
    result = qa_chain.invoke({"question": question})
    
    # æ¸…ç†è¾“å‡ºï¼ˆç§»é™¤å¯èƒ½æ®‹ç•™çš„æ¨¡æ¿æ ‡è®°å’Œå¤šä½™ç©ºç™½ï¼‰
    result = result.strip()
    
    print(f"\nğŸ“ å›ç­”:\n{result}")

    # æ˜¾ç¤ºæ¥æºæ–‡çŒ®ï¼ˆå¸¦ç›¸å…³æ€§è¯„åˆ†å’Œæ‘˜è¦é¢„è§ˆï¼‰
    print("\n" + "-"*80)
    print("ğŸ“š å‚è€ƒæ–‡çŒ®ï¼ˆæŒ‰ç›¸å…³æ€§æ’åºï¼‰:")
    print("-"*80)
    
    for i, (doc, score) in enumerate(filtered_docs, 1):
        title = doc.metadata.get('title', 'Unknown')
        pmid = doc.metadata.get('pmid', 'Unknown')
        journal = doc.metadata.get('journal', 'Unknown')
        pub_date = doc.metadata.get('pub_date', 'Unknown')
        
        print(f"\n[{i}] ç›¸å…³æ€§: {score:.2%}")
        print(f"    æ ‡é¢˜: {title}")
        print(f"    æœŸåˆŠ: {journal}")
        print(f"    å‘è¡¨: {pub_date}")
        print(f"    PMID: {pmid}")
        
        # æ˜¾ç¤ºæ–‡æ¡£ç‰‡æ®µï¼ˆå‰150å­—ç¬¦ï¼‰
        content_preview = doc.page_content[:150].replace('\n', ' ')
        print(f"    æ‘˜è¦: {content_preview}...")
    
    print("\n" + "="*80)


# 9. æµ‹è¯•ä¸€äº›åŒ»å­¦é—®é¢˜
test_questions = [
    "å¯Œè¡€å°æ¿è¡€æµ†ï¼ˆPRPï¼‰åœ¨æ²»ç–—è‚Œè…±æŸä¼¤ä¸­çš„æ•ˆæœå¦‚ä½•ï¼Ÿ",
    "å“ªäº›éª¨ç§‘ç”Ÿç‰©åˆ¶å‰‚å¯ç”¨äºæ²»ç–—è‚Œè‚‰æŸä¼¤ï¼Ÿ",
    "ä»€ä¹ˆæ˜¯å¿ƒåŒ…å¼‚ä½ç”²çŠ¶æ—è…ºè…ºç˜¤ï¼Ÿå®ƒåœ¨åŸå‘æ€§ç”²çŠ¶æ—è…ºåŠŸèƒ½äº¢è¿›ç—‡çš„è¯Šæ–­å’Œæ²»ç–—ä¸­ä¸ºä½•æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Ÿ"
]

for question in test_questions:
    ask_medical_question(question)

# 10. äº¤äº’å¼é—®ç­”
print("\n=== åŒ»ç–—æ–‡çŒ®RAGç³»ç»Ÿå·²å¯åŠ¨ ===")
print("è¾“å…¥ 'é€€å‡º' æ¥ç»“æŸå¯¹è¯")

while True:
    user_question = input("\nè¯·è¾“å…¥æ‚¨çš„åŒ»å­¦é—®é¢˜: ")
    if user_question.lower() in ['é€€å‡º', 'exit', 'quit']:
        break
    ask_medical_question(user_question)